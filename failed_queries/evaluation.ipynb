{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import NotebookLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotebookLoader(\n",
    "    \"../all_functions.ipynb\",\n",
    "    include_outputs=False,\n",
    "    remove_newline=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OllamaEmbeddings(model=\"llama3.1:8b-instruct-fp16\")\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of Germany?\n",
      "Answer: I don't know. The provided documents do not contain information about Germany's capital, but rather a function to retrieve a country's capital and a tip calculator for different countries' meal services.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template for the LLM\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "# Initialize the LLM with Llama 3.1 model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")\n",
    "# Create a chain combining the prompt template and LLM\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "# Define the RAG application class\n",
    "class RAGApplication:\n",
    "    def __init__(self, retriever, rag_chain):\n",
    "        self.retriever = retriever\n",
    "        self.rag_chain = rag_chain\n",
    "    def run(self, question):\n",
    "        # Retrieve relevant documents\n",
    "        documents = self.retriever.invoke(question)\n",
    "        # Extract content from retrieved documents\n",
    "        doc_texts = \"\\\\n\".join([doc.page_content for doc in documents])\n",
    "        # Get the answer from the language model\n",
    "        answer = self.rag_chain.invoke({\"question\": question, \"documents\": doc_texts})\n",
    "        return answer\n",
    "# Initialize the RAG application\n",
    "rag_application = RAGApplication(retriever, rag_chain)\n",
    "# Example usage\n",
    "question = \"What is the capital of Germany?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vectorstore.similarity_search_with_score(query))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(metadata={'id': '15de98e4-72ab-48e7-9c09-5905cacfd5a8', 'source': '../all_functions.ipynb', 'score': 0.7404258977853408}, page_content=\"str: A JSON string with the current time in PST, temperature, weather, and the city,', '             or an error message if the input is\"),\n",
       " Document(metadata={'id': 'e885a2fe-7d5d-4970-a4e1-274cb0f3cb45', 'source': '../all_functions.ipynb', 'score': 0.7428807921438789}, page_content=\"- 25% for excellent service', '    For other countries, the tip percentages are:', '        - 5% for poor service', '        - 10% for satisfactory\"),\n",
       " Document(metadata={'id': '5fd914d6-cc8b-4d41-8d76-2c8b2bb47531', 'source': '../all_functions.ipynb', 'score': 0.7768644949093271}, page_content='\\'    \"\"\"\\', \\'    Calculates the total duration of a playlist and returns the result as a JSON string.\\', \\'\\', \\'    This function computes the total duration of a playlist based on the number of songs'),\n",
       " Document(metadata={'id': '1a30fee1-b5f2-400f-a8c2-731568ca5da2', 'source': '../all_functions.ipynb', 'score': 0.7802176961760763}, page_content='\\'code\\' cell: \\'[\\'def get_timezone(city: str, state: str, country: str, mail_code: str) -> str:\\', \\'    \"\"\"\\', \\'    Determines the'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = retriever.invoke('What is the average airspeed velocity of a swallow')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802176961760763"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([i.metadata['score'] for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('failed_queries.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "max_values = []\n",
    "\n",
    "# Iterate over the queries and print each query\n",
    "for item in data[\"queries\"]:\n",
    "    result = retriever.invoke(item[\"query\"])\n",
    "    max_values.append(max([i.metadata['score'] for i in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7143435628245849"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_max_value = sum(max_values) / len(max_values)\n",
    "average_max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
