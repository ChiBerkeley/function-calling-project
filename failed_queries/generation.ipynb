{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_experimental.tabular_synthetic_data.base import (\n",
    "    SyntheticDataGenerator,\n",
    ")\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
    "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    ")\n",
    "from langchain_ollama import OllamaLLM, ChatOllama\n",
    "\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "    function: str\n",
    "    arguments: Dict[str, str]\n",
    "\n",
    "\n",
    "class func_calls(BaseModel):\n",
    "    query: str\n",
    "    answer: Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.1\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"example\": \"\"\"{{\"query\": \"What is your name\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"Where are you from\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"Change the channel to 5\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"What is 5 divided by 7\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"What phase is the moon going to be on 10/29/24\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"When is the next solar eclipse\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"},\n",
    "    {\"example\": \"\"\"{{\"query\": \"How many calories should I eat to loose 1/2lbs every two weeks as a man who weights 170lbs\", \"answer\": {{\"function\": \"no_such_function\", \"arguments\": {{}}}}}}\"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_json_quotes(json_str):\n",
    "    json_str = re.sub(r'\\\"([a-zA-Z]+)\\\"', r'\\\\\\\"\\1\\\\\\\"', json_str)\n",
    "    json_str = re.sub(r\"'([a-zA-Z])'\", r'\"\\1\"', json_str)\n",
    "\n",
    "    return json_str\n",
    "\n",
    "def validate_and_fix_json(json_str):\n",
    "    try:\n",
    "        parsed_data = json.loads(json_str)\n",
    "        return parsed_data\n",
    "    except json.JSONDecodeError:\n",
    "        fixed_json_str = fix_json_quotes(json_str)\n",
    "        try:\n",
    "            parsed_data = json.loads(fixed_json_str)\n",
    "            return parsed_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to fix JSON: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 56.50seconds to generate data\n",
      "Saved to dump_json/failed_10.json\n",
      "It took 64.94seconds to generate data\n",
      "Saved to dump_json/failed_11.json\n",
      "It took 47.83seconds to generate data\n",
      "Saved to dump_json/failed_12.json\n",
      "It took 45.25seconds to generate data\n",
      "Saved to dump_json/failed_13.json\n",
      "It took 42.97seconds to generate data\n",
      "Saved to dump_json/failed_14.json\n",
      "It took 53.91seconds to generate data\n",
      "Saved to dump_json/failed_15.json\n",
      "It took 59.65seconds to generate data\n",
      "Saved to dump_json/failed_16.json\n",
      "It took 48.48seconds to generate data\n",
      "Saved to dump_json/failed_17.json\n",
      "It took 54.00seconds to generate data\n",
      "Saved to dump_json/failed_18.json\n",
      "It took 64.25seconds to generate data\n",
      "Saved to dump_json/failed_19.json\n",
      "It took 52.91seconds to generate data\n",
      "Saved to dump_json/failed_20.json\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,21):\n",
    "    OPENAI_TEMPLATE = PromptTemplate.from_template(template=\"{example}\")\n",
    "\n",
    "    prompt_template = FewShotPromptTemplate(\n",
    "        prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "        examples=examples,\n",
    "        suffix=SYNTHETIC_FEW_SHOT_SUFFIX, \n",
    "        input_variables=[\"subject\", \"extra\"],\n",
    "        example_prompt=OPENAI_TEMPLATE,\n",
    "    )\n",
    "\n",
    "    synthetic_data_generator = SyntheticDataGenerator(template=prompt_template, llm=llm, output_schema=func_calls)\n",
    "\n",
    "    def generate_synthetic_data(runs=1):\n",
    "        \"\"\"\n",
    "        Generates synthetic data by invoking the synthetic_data_generator with specified parameters.\n",
    "        Args:\n",
    "            runs (int, optional): The number of times to run the data generation process. Defaults to 1 as anything more currently breaks the pipeline.\n",
    "        Returns:\n",
    "            list: A list of synthetic results generated by the synthetic_data_generator. Len(synthetic_results) == runs.\n",
    "        Example:\n",
    "            synthetic_results = generate_synthetic_data(runs=1)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        synthetic_results = synthetic_data_generator.generate(\n",
    "            subject = \"natural language queries for API functions that take 1-4 arguments. Report the function as no_such_function\",\n",
    "            extra = \"the arguments must be chosen at random. Make the entire query somewhat unique. Don't report the arguments. Don't repeat the same type of question. Don't make chit-chat and don't have an introduction. Generate 70 examples\",\n",
    "            runs=runs,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"It took {end_time - start_time:.2f}seconds to generate data\")\n",
    "        return synthetic_results\n",
    "\n",
    "    data = generate_synthetic_data(runs=1)\n",
    "    json_strings = data[0].split('\\n\\n')\n",
    "\n",
    "    parsed_json_objects = []\n",
    "    for json_str in json_strings:\n",
    "        fixed_json = validate_and_fix_json(json_str)\n",
    "        if fixed_json:\n",
    "            parsed_json_objects.append(fixed_json)\n",
    "        else:\n",
    "            print(f\"Skipping invalid JSON string: {json_str}\")\n",
    "\n",
    "    combined_json = json.dumps({\"queries\": parsed_json_objects}, indent=4)\n",
    "\n",
    "    with open(f'dump_json/failed_{i}.json', 'w') as json_file:\n",
    "        json_file.write(combined_json)\n",
    "    print(f\"Saved to dump_json/failed_{i}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique queries written to failed_queries.json\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Combines multiple JSON files into a single  #\n",
    "# JSON file with unique queries               #\n",
    "# Written by ChatGPT                          #\n",
    "###############################################\n",
    "\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Directory where JSON files are located\n",
    "json_dir = 'dump_json'\n",
    "\n",
    "# Set to store unique queries\n",
    "unique_queries = set()\n",
    "\n",
    "# List to store the final output\n",
    "final_queries = []\n",
    "\n",
    "\n",
    "# Function to process each JSON file\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for query_obj in data.get(\"queries\", []):\n",
    "            # Convert query dict to a string for comparison\n",
    "            query_str = json.dumps(query_obj, sort_keys=True)\n",
    "            if query_str not in unique_queries:\n",
    "                unique_queries.add(query_str)\n",
    "                final_queries.append(query_obj)\n",
    "\n",
    "\n",
    "# Read all JSON files\n",
    "for json_file in glob(os.path.join(json_dir, '*.json')):\n",
    "    process_json_file(json_file)\n",
    "\n",
    "# Output the final result to a new file\n",
    "output_data = {\"queries\": final_queries}\n",
    "output_file = 'failed_queries.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)\n",
    "\n",
    "print(f'Unique queries written to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
