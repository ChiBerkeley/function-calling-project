{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(\"bedrock-runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant trained to assist\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explain the process of backpropagation in nerual networks.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nAccording to the information I have, the weather in USA is currently Sunday.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '59360e82-a97b-4fb2-938f-44fd800d1164', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 13 Oct 2024 00:19:55 GMT', 'content-type': 'application/json', 'content-length': '261', 'connection': 'keep-alive', 'x-amzn-requestid': '59360e82-a97b-4fb2-938f-44fd800d1164'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': 372}}, id='run-007158fd-1f1d-464b-b3d4-60348420d2ec-0', usage_metadata={'input_tokens': 55, 'output_tokens': 17, 'total_tokens': 72})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from botocore.config import Config\n",
    "\n",
    "retry_config = Config(\n",
    "    retries = {\n",
    "        'max_attempts': 20,  # Customize the number of retry attempts\n",
    "        'mode': 'adaptive'   # Or 'adaptive' for dynamically adjusting retries\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the Bedrock client with retry configuration\n",
    "bedrock_client = boto3.client('bedrock-runtime', config=retry_config)\n",
    "\n",
    "# Use the ChatBedrock model in LangChain with the client that has retries\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"meta.llama3-1-8b-instruct-v1:0\",  # Or \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "    temperature=0.4,\n",
    "    max_tokens=None)\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a bot and you should reply to the user based on the function calling return. The return is {'weather': 'Sunday', 'location': 'USA'}\"),\n",
    "    (\"user\", \"what is the weather in USA now?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"[{\n",
    "  \"query\": \"How many times does the letter 'a' appear in the word 'banana'?\",\n",
    "  \"answer\": {\n",
    "    \"function\": \"count_letter\",\n",
    "    \"arguments\": {\n",
    "      \"word\": \"banana\",\n",
    "      \"letter\": \"a\"\n",
    "    },\n",
    "    \"result\": {\n",
    "      \"result\": \"3\"\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"query\": \"How many times does the letter 'e' appear in the word 'computer'?\",\n",
    "  \"answer\": {\n",
    "    \"function\": \"count_letter\",\n",
    "    \"arguments\": {\n",
    "      \"word\": \"computer\",\n",
    "      \"letter\": \"e\"\n",
    "    },\n",
    "    \"result\": {\n",
    "      \"result\": \"2\"\n",
    "    }\n",
    "  }\n",
    "}]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kevin_function import count_letter\n",
    "\n",
    "## read test file\n",
    "with open (\"ks_instruct/test.txt\", \"r\") as file:\n",
    "    text = file.read() # it cannot be read currently\n",
    "\n",
    "example = json.loads(example_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_function(info: dict):\n",
    "    query = info[\"query\"]\n",
    "    answer = info[\"answer\"]\n",
    "    func_to_call = eval(answer[\"function\"])\n",
    "    arguments = answer[\"arguments\"]\n",
    "    return {\"query\": query, \"output\": func_to_call(**arguments)}\n",
    "\n",
    "def generate_response(query_output, llm):\n",
    "    messages = [\n",
    "    (\"system\", f\"You are a bot and you should reply to the user based on the function calling return. The return is {query_output['output']}\"),\n",
    "    (\"user\", query_output[\"query\"])]\n",
    "    response = llm.invoke(messages)\n",
    "    query_output[\"response\"] = response.content\n",
    "    return query_output\n",
    "\n",
    "query_output = call_function(example[0])\n",
    "query_response = generate_response(query_output, llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"How many times does the letter 'a' appear in the word 'banana'?\",\n",
       " 'answer': {'function': 'count_letter',\n",
       "  'arguments': {'word': 'banana', 'letter': 'a'},\n",
       "  'result': {'result': '3'}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query_response\n",
    "example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Given the text, breakdown and generate a list of statements presented. Ambiguous statements and single words can \n",
       "also be considered as statements.\n",
       "\n",
       "Example:\n",
       "Example text: Shoes. The shoes can be refunded at no extra cost. Thanks for asking the question!\n",
       "\n",
       "{\n",
       "    \"statements\": [\"Shoes.\", \"Shoes can be refunded at no extra cost\", \"Thanks for asking the question!\"]\n",
       "}\n",
       "===== END OF EXAMPLE ======\n",
       "        \n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the \"statements\" key mapping to a list of strings. \n",
       "No words or explanation is needed.\n",
       "**\n",
       "\n",
       "Text:\n",
       "The letter 'a' appears 3 times in the word 'banana'.\n",
       "\n",
       "JSON:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Given the text, breakdown and generate a list of statements presented. Ambiguous statements and single words can \n",
       "also be considered as statements.\n",
       "\n",
       "Example:\n",
       "Example text: Shoes. The shoes can be refunded at no extra cost. Thanks for asking the question!\n",
       "\n",
       "{\n",
       "    \"statements\": [\"Shoes.\", \"Shoes can be refunded at no extra cost\", \"Thanks for asking the question!\"]\n",
       "}\n",
       "===== END OF EXAMPLE ======\n",
       "        \n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the \"statements\" key mapping to a list of strings. \n",
       "No words or explanation is needed.\n",
       "**\n",
       "\n",
       "Text:\n",
       "The letter 'a' appears 3 times in the word 'banana'.\n",
       "\n",
       "JSON:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For the provided list of statements, determine whether each statement is relevant to address the input.\n",
       "Please generate a list of JSON with two keys: `verdict` and `reason`.\n",
       "The 'verdict' key should STRICTLY be either a 'yes', 'idk' or 'no'. Answer 'yes' if the statement is relevant to \n",
       "addressing the original input, 'no' if the statement is irrelevant, and 'idk' if it is ambiguous (eg., not directly\n",
       "relevant but could be used as a supporting point to address the input).\n",
       "The 'reason' is the reason for the verdict.\n",
       "Provide a 'reason' ONLY if the answer is 'no'. \n",
       "The provided statements are statements made in the actual output.\n",
       "\n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the 'verdicts' key mapping to a list of JSON \n",
       "objects.\n",
       "Example input: What should I do if there is an earthquake?\n",
       "Example statements: [\"Shoes.\", \"Thanks for asking the question!\", \"Is there anything else I can help you with?\", \n",
       "\"Duck and hide\"]\n",
       "Example JSON:\n",
       "{\n",
       "    \"verdicts\": [\n",
       "        {\n",
       "            \"verdict\": \"no\",\n",
       "            \"reason\": \"The 'Shoes.' statement made in the actual output is completely irrelevant to the input, \n",
       "which asks about what to do in the event of an earthquake.\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"idk\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"idk\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"yes\"\n",
       "        }\n",
       "    ]  \n",
       "}\n",
       "\n",
       "Since you are going to generate a verdict for each statement, the number of 'verdicts' SHOULD BE STRICTLY EQUAL to \n",
       "the number of `statements`.\n",
       "**          \n",
       "\n",
       "Input:\n",
       "How many times does the letter 'a' appear in the word 'banana'?\n",
       "\n",
       "Statements:\n",
       "[\"The letter 'a' appears 3 times in the word 'banana'.\"]\n",
       "\n",
       "JSON:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For the provided list of statements, determine whether each statement is relevant to address the input.\n",
       "Please generate a list of JSON with two keys: `verdict` and `reason`.\n",
       "The 'verdict' key should STRICTLY be either a 'yes', 'idk' or 'no'. Answer 'yes' if the statement is relevant to \n",
       "addressing the original input, 'no' if the statement is irrelevant, and 'idk' if it is ambiguous (eg., not directly\n",
       "relevant but could be used as a supporting point to address the input).\n",
       "The 'reason' is the reason for the verdict.\n",
       "Provide a 'reason' ONLY if the answer is 'no'. \n",
       "The provided statements are statements made in the actual output.\n",
       "\n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the 'verdicts' key mapping to a list of JSON \n",
       "objects.\n",
       "Example input: What should I do if there is an earthquake?\n",
       "Example statements: [\"Shoes.\", \"Thanks for asking the question!\", \"Is there anything else I can help you with?\", \n",
       "\"Duck and hide\"]\n",
       "Example JSON:\n",
       "{\n",
       "    \"verdicts\": [\n",
       "        {\n",
       "            \"verdict\": \"no\",\n",
       "            \"reason\": \"The 'Shoes.' statement made in the actual output is completely irrelevant to the input, \n",
       "which asks about what to do in the event of an earthquake.\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"idk\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"idk\"\n",
       "        },\n",
       "        {\n",
       "            \"verdict\": \"yes\"\n",
       "        }\n",
       "    ]  \n",
       "}\n",
       "\n",
       "Since you are going to generate a verdict for each statement, the number of 'verdicts' SHOULD BE STRICTLY EQUAL to \n",
       "the number of `statements`.\n",
       "**          \n",
       "\n",
       "Input:\n",
       "How many times does the letter 'a' appear in the word 'banana'?\n",
       "\n",
       "Statements:\n",
       "[\"The letter 'a' appears 3 times in the word 'banana'.\"]\n",
       "\n",
       "JSON:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Given the answer relevancy score, the list of reasons of irrelevant statements made in the actual output, and the \n",
       "input, provide a CONCISE reason for the score. Explain why it is not higher, but also why it is at its current \n",
       "score.\n",
       "The irrelevant statements represent things in the actual output that is irrelevant to addressing whatever is \n",
       "asked/talked about in the input.\n",
       "If there is nothing irrelevant, just say something positive with an upbeat encouraging tone (but don't overdo it \n",
       "otherwise it gets annoying).\n",
       "\n",
       "\n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the 'reason' key providing the reason.\n",
       "Example JSON:\n",
       "{\n",
       "    \"reason\": \"The score is &lt;answer_relevancy_score&gt; because &lt;your_reason&gt;.\"\n",
       "}\n",
       "**\n",
       "\n",
       "Answer Relevancy Score:\n",
       "1.00\n",
       "\n",
       "Reasons why the score can't be higher based on irrelevant statements in the actual output:\n",
       "[]\n",
       "\n",
       "Input:\n",
       "How many times does the letter 'a' appear in the word 'banana'?\n",
       "\n",
       "JSON:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Given the answer relevancy score, the list of reasons of irrelevant statements made in the actual output, and the \n",
       "input, provide a CONCISE reason for the score. Explain why it is not higher, but also why it is at its current \n",
       "score.\n",
       "The irrelevant statements represent things in the actual output that is irrelevant to addressing whatever is \n",
       "asked/talked about in the input.\n",
       "If there is nothing irrelevant, just say something positive with an upbeat encouraging tone (but don't overdo it \n",
       "otherwise it gets annoying).\n",
       "\n",
       "\n",
       "**\n",
       "IMPORTANT: Please make sure to only return in JSON format, with the 'reason' key providing the reason.\n",
       "Example JSON:\n",
       "{\n",
       "    \"reason\": \"The score is <answer_relevancy_score> because <your_reason>.\"\n",
       "}\n",
       "**\n",
       "\n",
       "Answer Relevancy Score:\n",
       "1.00\n",
       "\n",
       "Reasons why the score can't be higher based on irrelevant statements in the actual output:\n",
       "[]\n",
       "\n",
       "Input:\n",
       "How many times does the letter 'a' appear in the word 'banana'?\n",
       "\n",
       "JSON:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.12/lib/python3.12/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "The score is 1.00 because the actual output directly answers the question about the frequency of the letter 'a' in the word 'banana', making it highly relevant and accurate.\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "class AWSBedrock(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        print(prompt)\n",
    "        chat_model = self.load_model()\n",
    "        res = chat_model.invoke(prompt).content\n",
    "        return res\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"llama-3-1-8b\"\n",
    "\n",
    "aws_bedrock = AWSBedrock(model=llm)\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.3,\n",
    "    model=aws_bedrock,\n",
    "    include_reason=True,\n",
    "    async_mode=False\n",
    ")\n",
    "\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=query_response[\"query\"],\n",
    "    actual_output= query_response[\"response\"]\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "# evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cs/Library/Caches/pypoetry/virtualenvs/function-calling-project-_d8EX7TE-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': [\"How many times does the letter 'a' appear in the word 'banana'?\",\n",
       "  \"What is the frequency of the letter 'a' in the word 'banana'?\",\n",
       "  \"How often does the letter 'a' appear in the word 'banana'?\"]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse prompt engineering\n",
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    \"\"\"reverse prompt engineering output\"\"\"\n",
    "    query: List[str] = Field(description=\"list of queries according to the user repsonse\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Query)\n",
    "\n",
    "def get_reverse_prompt(n, query_response, llm):\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Guess \" + str(n) + \"most possible queries based on a user's response.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    query_response[\"response\"]\n",
    "    prompt_and_model = prompt | llm\n",
    "    output = prompt_and_model.invoke({\"query\": query_response[\"response\"]})\n",
    "\n",
    "    return parser.invoke(output)\n",
    "\n",
    "def calculate_mean_similiarity(query_response, reverse_queries):\n",
    "    model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "    # def get_cos_sim(query_response, reverse_queries):\n",
    "    embedding = BedrockEmbeddings(model_id=model_id)\n",
    "    original_embedded = embedding.embed_query(query_response[\"query\"])\n",
    "    guess_embeded = embedding.embed_documents(reverse_queries[\"query\"])\n",
    "    return np.array([cosine_similarity([original_embedded], [item])[0] for item in guess_embeded]).mean()\n",
    "\n",
    "reverse_queries = get_reverse_prompt(3, query_response, llm)\n",
    "reverse_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"How many times does the letter 'a' appear in the word 'banana'?\",\n",
       " 'output': '{\"result\": 3}',\n",
       " 'response': \"The letter 'a' appears 3 times in the word 'banana'.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/cso/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-package\n",
       "s/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "The score is 0.50 because the actual output incorrectly claims the function count_letter is to be called, and also incorrectly identifies the first and second parameters as 'pear' and 'b' respectively, which are not mentioned in the retrieval context.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3</span><span style=\"color: #374151; text-decoration-color: #374151\">-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">1</span><span style=\"color: #374151; text-decoration-color: #374151\">-8b, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama-\u001b[0m\u001b[1;38;2;55;65;81m3\u001b[0m\u001b[38;2;55;65;81m-\u001b[0m\u001b[1;38;2;55;65;81m1\u001b[0m\u001b[38;2;55;65;81m-8b, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |          |  0% (0/1) [Time Taken: 00:00, ?test case/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:04,  4.06s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Faithfulness (score: 0.6666666666666666, threshold: 0.7, strict: False, evaluation model: llama-3-1-8b, reason: The score is 0.67 because the actual output contains errors: the function to be called is incorrect and the first parameter is also incorrect, indicating a moderate level of faithfulness to the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Which function and argument I should call if I ask: How many times does the letter 'a' appear in the word 'banana'?\n",
      "  - actual output: We should call a function named count_letter('pear', 'b'))\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['\\n    Counts the number of occurrences of a specified letter in a word.\\n\\n    Parameters:\\n    word (str): The word to count letters in.\\n    letter (str): The letter to count.\\n\\n    Example:\\n    >>> count_letter(\\'strawberry\\', \\'R\\')\\n    \\'{\"result\": 3}\\'\\n    ']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Faithfulness: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to view evaluation results on Confident AI. \n",
       "‚ÄºÔ∏è  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[32m'deepeval login'\u001b[0m to view evaluation results on Confident AI. \n",
       "‚ÄºÔ∏è  NOTE: You can also run evaluations on ALL of deepeval's metrics directly on Confident AI instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestResult(success=False, metrics_data=[MetricData(name='Faithfulness', threshold=0.7, success=False, score=0.6666666666666666, reason='The score is 0.67 because the actual output contains errors: the function to be called is incorrect and the first parameter is also incorrect, indicating a moderate level of faithfulness to the retrieval context.', strict_mode=False, evaluation_model='llama-3-1-8b', error=None, evaluation_cost=None, verbose_logs='Truths (limit=None):\\n[\\n    \"A function to count the number of occurrences of a specified letter in a word exists.\",\\n    \"The function takes two parameters: \\'word\\' and \\'letter\\'.\",\\n    \"The function returns a JSON object.\"\\n] \\n \\nClaims:\\n[\\n    \"We should call a function named count_letter(\\'pear\\', \\'b\\'))\",\\n    \"A function named count_letter exists\",\\n    \"The function count_letter takes two parameters\",\\n    \"The first parameter of the function count_letter is \\'pear\\'\",\\n    \"The second parameter of the function count_letter is \\'b\\'\",\\n    \"The function count_letter is to be called\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The actual output claims the function count_letter is to be called, which is not correct as the retrieval context states the function count_letter exists instead.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The actual output claims the first parameter of the function count_letter is \\'pear\\', which is not correct as the retrieval context does not mention the first parameter.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input=\"Which function and argument I should call if I ask: How many times does the letter 'a' appear in the word 'banana'?\", actual_output=\"We should call a function named count_letter('pear', 'b'))\", expected_output=None, context=None, retrieval_context=['\\n    Counts the number of occurrences of a specified letter in a word.\\n\\n    Parameters:\\n    word (str): The word to count letters in.\\n    letter (str): The letter to count.\\n\\n    Example:\\n    >>> count_letter(\\'strawberry\\', \\'R\\')\\n    \\'{\"result\": 3}\\'\\n    '])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# {'query': \"How many times does the letter 'a' appear in the word 'banana'?\",\n",
    "#  'answer': {'function': 'count_letter',\n",
    "#   'arguments': {'word': 'banana', 'letter': 'a'},\n",
    "#   'result': {'result': '3'}}}\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We should call a function named count_letter('pear', 'b'))\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [count_letter.__doc__]\n",
    "\n",
    "metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=aws_bedrock,\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Which function and argument I should call if I ask: How many times does the letter 'a' appear in the word 'banana'?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "# evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Counts the number of occurrences of a specified letter in a word.\\n\\n    Parameters:\\n    word (str): The word to count letters in.\\n    letter (str): The letter to count.\\n\\n    Example:\\n    >>> count_letter(\\'strawberry\\', \\'R\\')\\n    \\'{\"result\": 3}\\'\\n    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_letter.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"The letter 'a' appears 3 times in the word 'banana'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-074ca9e3-8d8d-4ceb-80c6-3cc71304fb83-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'e' appears once in the word 'computer'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-7cad2446-14ba-464d-9153-2b0e9de69985-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The word 'telescope' contains the letter 't' two times.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-cceae45f-ce09-4708-83d3-535686f37581-0', usage_metadata={'input_tokens': 60, 'output_tokens': 16, 'total_tokens': 76}),\n",
       " AIMessage(content=\"The letter 'r' appears 1 time in the word 'rainbow'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-d35f3346-5e77-4113-8b09-6ff7db3d13e8-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'o' appears 2 times in the word 'ocean'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-0e0365ca-b786-46ac-9fe7-5670e430e462-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'b' appears 2 times in the word 'bubble'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ed10d1c8-fce4-4f95-b862-9065f2aa90cd-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'p' appears 2 times in the word 'paper'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-277423d4-edf3-4ec0-95a4-eaeb80813480-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 's' appears 2 times in the word 'space'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-cd7a59ae-5fc3-462d-8344-ce948bafc3ef-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'd' appears 1 time in the word 'dog'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-97decd8a-4815-4ef0-88b3-724448695a0c-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'f' appears once in the word 'fish'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-108010f2-c726-4509-84a5-7c6fbf2a4287-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'c' appears once in the word 'cat'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-649c700c-88a6-49ba-bc02-5cf92f43a31c-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'h' appears once in the word 'house'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-d09f77b2-a30e-4125-bcf8-09ae754650b0-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'm' appears once in the word 'mouse'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-cf7ee8df-da8a-4f50-a83e-fcc89f066e1f-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'n' appears 1 time in the word 'nest'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-1973ad6e-050b-41a3-9155-5d0a753f6090-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'v' appears once in the word 'vase'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-49724d91-d3cb-4712-8ab2-3ecdc227b22b-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'z' appears only once in the word 'zebra'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-05529bad-2506-4f5b-b4ce-165e1faec57e-0', usage_metadata={'input_tokens': 60, 'output_tokens': 16, 'total_tokens': 76}),\n",
       " AIMessage(content=\"The letter 'q' appears once in the word 'queen'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ff48e8b4-0055-4e94-bb9d-9e7d0a612190-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'j' appears once in the word 'jug'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-5c691412-279b-4013-8fbd-9d65c45ce8b8-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'k' appears once in the word 'kite'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-259f115f-dbff-429f-919b-8231d4dd6517-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'x' appears once in the word 'fox'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-22db7cb6-db97-4a8c-a5c7-0fb1d61a17bb-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'y' appears once in the word 'yes'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-bfb06e80-b8dd-4959-98bb-88c43fbeba86-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'u' appears twice in the word 'umbrella'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-afdaf2b6-2118-4286-be45-40a8f7b59a3b-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'e' appears 2 times in the word 'elephant'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ac42e3da-6fc0-403c-a93c-0a75b288714c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'a' appears once in the word 'apple'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-b92e029d-95b8-49d1-bdf0-0dc601bc62d1-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'i' appears 2 times in the word 'igloo'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-19688924-d1ed-4fe8-be18-8be31b32b331-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'w' appears once in the word 'whale'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-f6de0ede-91c6-4f36-93ef-5a47613e30cb-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'g' appears once in the word 'girl'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-34c906b1-8bd7-469a-83bd-32b07fcd158e-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'l' appears twice in the word 'lion'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-687e0695-df12-4603-b1a4-2825adc2c605-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'o' appears 2 times in the word 'ocean'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-992667f6-236e-47ad-8a88-0fec127e479d-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'p' appears 2 times in the word 'paper'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-a501da52-7a88-4ce6-95fa-2f55ca6e7bd5-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 't' appears 1 time in the word 'tree'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-05fb93ff-ea30-4416-9f8c-e7cb01529d35-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'r' appears 1 time in the word 'rainbow'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-80420c81-9f19-40dd-bacc-ba75911d8be0-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 's' appears 1 time in the word 'sunshine'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-41611fe3-edc3-42be-a284-abde087de0dc-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'f' appears twice in the word 'flower'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ed9ee3a8-73a1-46c5-a3c8-920942def7d6-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'h' appears once in the word 'house'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-6a500755-c5b6-4721-9cf1-f6c035489aef-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'c' appears once in the word 'cloud'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-99151754-14a6-4a65-97f4-c0bbad177b13-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'm' appears 2 times in the word 'moments'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ef34c1e5-288e-4ec1-a1f1-d3da11fd20c5-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'v' appears 1 time in the word 'victory'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-25ac6075-a0c9-4584-a223-8d93296b39e6-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'b' appears 2 times in the word 'bubble'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-937cd2bc-2736-4a61-81f1-06c90663f042-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'd' appears 1 time in the word 'dance'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 16, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ada8a318-7f0f-47e7-93d1-03d938358583-0', usage_metadata={'input_tokens': 59, 'output_tokens': 16, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'z' appears only once in the word 'zebra'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-8793dfe2-50c9-4bd3-9c87-eedbeb666ff5-0', usage_metadata={'input_tokens': 60, 'output_tokens': 16, 'total_tokens': 76}),\n",
       " AIMessage(content=\"The word 'night' has 1 'n'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 12, 'total_tokens': 71}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 12, 'total_tokens': 71}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-b60b181b-9c09-47a8-9b11-3fc84df2cc4d-0', usage_metadata={'input_tokens': 59, 'output_tokens': 12, 'total_tokens': 71}),\n",
       " AIMessage(content=\"The letter 'p' appears once in the word 'pink'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-70aaf37b-bf5c-4ec5-b1ad-d5ccea3b0a00-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'q' appears once in the word 'queen'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-b4d30c4c-d523-4ac9-8d69-64c79b80eb87-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'w' appears once in the word 'water'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-a888dfb8-ec26-4b5d-a7e7-bbf2198f2268-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The word 'xylophone' contains the letter 'x' twice.\", additional_kwargs={'usage': {'prompt_tokens': 61, 'completion_tokens': 16, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 61, 'completion_tokens': 16, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-13a0b5f0-485b-46e0-813a-060a2baf87ea-0', usage_metadata={'input_tokens': 61, 'output_tokens': 16, 'total_tokens': 77}),\n",
       " AIMessage(content='The letter \\'y\\' appears only once in the word \"yacht\".', additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 16, 'total_tokens': 76}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-c426b4a8-493c-4373-935a-9d1c9106920c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 16, 'total_tokens': 76}),\n",
       " AIMessage(content=\"The letter 'u' appears 1 time in the word 'umbrella'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-9ea41959-38d9-4e40-ad54-cbf89ff0cede-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'j' appears once in the word 'jester'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ad0b1f94-7017-439b-b21b-dc9dd063189c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'k' appears once in the word 'knight'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-458cf6e6-6e2a-402b-87fa-7f29eb0f00ff-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'i' appears 2 times in the word 'igloo'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-ebcd5cfb-c6b1-4f52-8c8c-0444348f090c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'a' appears once in the word 'apple'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-58643cea-0325-4e27-afae-3ab8df71d01e-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'e' appears 2 times in the word 'elephant'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-05529f6b-78d0-48e2-a0c7-8c6b0041b39f-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'o' appears 2 times in the word 'ocean'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-edf63bb7-be36-4a84-9841-e7720c01afea-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'l' appears twice in the word 'lake'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-f8df40de-f83e-4855-9b1c-f530c3de3b7a-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'g' appears once in the word 'goose'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-5b6bc6ba-e534-459d-9a46-1283f1019339-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'T' appears twice in the word 'tiger'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-8b52b9f9-e74c-47d1-9c50-421f0d4bd733-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The word 'snake' contains 1 'S'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 12, 'total_tokens': 71}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 12, 'total_tokens': 71}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-065fc455-ee24-4196-89f2-8e05303ece68-0', usage_metadata={'input_tokens': 59, 'output_tokens': 12, 'total_tokens': 71}),\n",
       " AIMessage(content=\"The letter 'P' appears 1 time in the word 'penguin'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-8f57934e-041a-4fd0-8397-c83dd72048b9-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'C' appears 1 time in the word 'chameleon'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-24bfd829-ce08-45cc-90c2-942386f67dc7-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'M' appears once in the word 'monkey'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-dc7184a9-9eac-41b3-8748-e96405b2516e-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'N' appears twice in the word 'ninja'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-13ee008f-c91a-4a46-84b8-fb77b81d6d27-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'F' appears once in the word 'fox'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-43ddb126-e6da-4591-9764-56b8500d1bc1-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'H' appears once in the word 'hen'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-1add1b91-7b08-4752-bdbc-c3831a65fdd2-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'R' appears once in the word 'rhino'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 15, 'total_tokens': 75}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-3f2e4393-93a3-48cc-8778-3822e3c2aec0-0', usage_metadata={'input_tokens': 60, 'output_tokens': 15, 'total_tokens': 75}),\n",
       " AIMessage(content=\"The letter 'D' appears once in the word 'dog'.\", additional_kwargs={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 59, 'completion_tokens': 14, 'total_tokens': 73}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-932783d1-a4e8-4cb4-a57b-075defc9541a-0', usage_metadata={'input_tokens': 59, 'output_tokens': 14, 'total_tokens': 73}),\n",
       " AIMessage(content=\"The letter 'V' appears 1 time in the word 'vulture'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-fbdc5f72-7a0c-4367-bd63-d63bf6f581e6-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77}),\n",
       " AIMessage(content=\"The letter 'Z' appears 1 time in the word 'zebra'.\", additional_kwargs={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 60, 'completion_tokens': 17, 'total_tokens': 77}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-8b-instruct-v1:0'}, id='run-9014b593-1e07-4996-ab6b-c2084e6ec6b3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.evaluation import call_function\n",
    "import asyncio\n",
    "with open(\"ks_instruct/test.txt\", \"r\") as file:\n",
    "    texts = json.load(file)\n",
    "texts\n",
    "\n",
    "# Invoke the call_function on each item\n",
    "batch_func = [call_function(item) for item in texts]\n",
    "\n",
    "# Adjust system prompt formatting\n",
    "system_prompt = \"You are a bot and you should reply to the user based on the function calling return. The return is {output}\"\n",
    "\n",
    "# Build batch message with correct formatting\n",
    "batch_message = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.format(output=item[\"output\"])}, \n",
    "        {\"role\": \"user\", \"content\": item[\"query\"]}\n",
    "    ]\n",
    "    for item in batch_func\n",
    "]\n",
    "\n",
    "# Perform batch invoke using the correct message structure\n",
    "responses = asyncio.run(llm.abatch(batch_message))\n",
    "responses\n",
    "# query_output[\"response\"] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using llama-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3</span><span style=\"color: #374151; text-decoration-color: #374151\">-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">1</span><span style=\"color: #374151; text-decoration-color: #374151\">-8b, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing llama-\u001b[0m\u001b[1;38;2;55;65;81m3\u001b[0m\u001b[38;2;55;65;81m-\u001b[0m\u001b[1;38;2;55;65;81m1\u001b[0m\u001b[38;2;55;65;81m-8b, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 68 test case(s) in parallel: |          |  0% (0/68) [Time Taken: 00:00, ?test case/s]ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "Evaluating 68 test case(s) in parallel: |          |  0% (0/68) [Time Taken: 00:09, ?test case/s]\n"
     ]
    },
    {
     "ename": "ThrottlingException",
     "evalue": "An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/metrics/answer_relevancy/answer_relevancy.py:240\u001b[0m, in \u001b[0;36mAnswerRelevancyMetric._a_generate_statements\u001b[0;34m(self, actual_output)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     res: Statements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStatements\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatements\n",
      "\u001b[0;31mTypeError\u001b[0m: AWSBedrock.a_generate() got an unexpected keyword argument 'schema'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mThrottlingException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     test_cases\u001b[38;5;241m.\u001b[39mappend(test_case)\n\u001b[1;32m     20\u001b[0m dataset \u001b[38;5;241m=\u001b[39m EvaluationDataset(test_cases\u001b[38;5;241m=\u001b[39mtest_cases)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/dataset/dataset.py:175\u001b[0m, in \u001b[0;36mEvaluationDataset.evaluate\u001b[0;34m(self, metrics)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cases) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo test cases found in evaluation dataset. Unable to evaluate empty dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/evaluate.py:1028\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(test_cases, metrics, hyperparameters, run_async, show_indicator, print_results, write_cache, use_cache, ignore_errors, skip_on_missing_params, verbose_mode, throttle_value, max_concurrent)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_async:\n\u001b[1;32m   1027\u001b[0m     loop \u001b[38;5;241m=\u001b[39m get_or_create_event_loop()\n\u001b[0;32m-> 1028\u001b[0m     test_results \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma_execute_test_cases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_to_disk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_indicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_indicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_on_missing_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_on_missing_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthrottle_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrottle_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_concurrent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_concurrent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m     test_results \u001b[38;5;241m=\u001b[39m execute_test_cases(\n\u001b[1;32m   1044\u001b[0m         test_cases,\n\u001b[1;32m   1045\u001b[0m         metrics,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         show_indicator\u001b[38;5;241m=\u001b[39mshow_indicator,\n\u001b[1;32m   1052\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:234\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/evaluate.py:657\u001b[0m, in \u001b[0;36ma_execute_test_cases\u001b[0;34m(test_cases, metrics, ignore_errors, skip_on_missing_params, use_cache, show_indicator, throttle_value, max_concurrent, save_to_disk, verbose_mode, test_run_manager, _use_bar_indicator)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     tasks\u001b[38;5;241m.\u001b[39mappend(asyncio\u001b[38;5;241m.\u001b[39mcreate_task(task))\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(throttle_value)\n\u001b[0;32m--> 657\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_case \u001b[38;5;129;01min\u001b[39;00m test_cases:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:234\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/evaluate.py:553\u001b[0m, in \u001b[0;36ma_execute_test_cases.<locals>.execute_with_semaphore\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_with_semaphore\u001b[39m(func: Callable, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[0;32m--> 553\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/evaluate.py:764\u001b[0m, in \u001b[0;36ma_execute_llm_test_cases\u001b[0;34m(metrics, test_case, test_run_manager, test_results, count, test_run, ignore_errors, skip_on_missing_params, use_cache, show_indicator, _use_bar_indicator, pbar)\u001b[0m\n\u001b[1;32m    762\u001b[0m new_cached_test_case: CachedTestCase \u001b[38;5;241m=\u001b[39m CachedTestCase()\n\u001b[1;32m    763\u001b[0m test_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m measure_metrics_with_indicator(\n\u001b[1;32m    765\u001b[0m     metrics\u001b[38;5;241m=\u001b[39mmetrics,\n\u001b[1;32m    766\u001b[0m     test_case\u001b[38;5;241m=\u001b[39mtest_case,\n\u001b[1;32m    767\u001b[0m     cached_test_case\u001b[38;5;241m=\u001b[39mcached_test_case,\n\u001b[1;32m    768\u001b[0m     skip_on_missing_params\u001b[38;5;241m=\u001b[39mskip_on_missing_params,\n\u001b[1;32m    769\u001b[0m     ignore_errors\u001b[38;5;241m=\u001b[39mignore_errors,\n\u001b[1;32m    770\u001b[0m     show_indicator\u001b[38;5;241m=\u001b[39mshow_metrics_indicator,\n\u001b[1;32m    771\u001b[0m )\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mskipped:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/metrics/indicator.py:200\u001b[0m, in \u001b[0;36mmeasure_metrics_with_indicator\u001b[0;34m(metrics, test_case, cached_test_case, ignore_errors, skip_on_missing_params, show_indicator)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m         tasks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    195\u001b[0m             safe_a_measure(\n\u001b[1;32m    196\u001b[0m                 metric, test_case, ignore_errors, skip_on_missing_params\n\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m         )\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/metrics/indicator.py:210\u001b[0m, in \u001b[0;36msafe_a_measure\u001b[0;34m(metric, tc, ignore_errors, skip_on_missing_params)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_a_measure\u001b[39m(\n\u001b[1;32m    204\u001b[0m     metric: Union[BaseMetric, BaseMultimodalMetric, BaseConversationalMetric],\n\u001b[1;32m    205\u001b[0m     tc: Union[LLMTestCase, MLLMTestCase, ConversationalTestCase],\n\u001b[1;32m    206\u001b[0m     ignore_errors: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    207\u001b[0m     skip_on_missing_params: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m metric\u001b[38;5;241m.\u001b[39ma_measure(tc, _show_indicator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MissingTestCaseParamsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m skip_on_missing_params:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/metrics/answer_relevancy/answer_relevancy.py:95\u001b[0m, in \u001b[0;36mAnswerRelevancyMetric.a_measure\u001b[0;34m(self, test_case, _show_indicator)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musing_native_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m metric_progress_indicator(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m, async_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _show_indicator\u001b[38;5;241m=\u001b[39m_show_indicator\n\u001b[1;32m     94\u001b[0m ):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatements: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a_generate_statements(\n\u001b[1;32m     96\u001b[0m         test_case\u001b[38;5;241m.\u001b[39mactual_output\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverdicts: List[AnswerRelvancyVerdict] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a_generate_verdicts(test_case\u001b[38;5;241m.\u001b[39minput)\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_score()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/deepeval/metrics/answer_relevancy/answer_relevancy.py:245\u001b[0m, in \u001b[0;36mAnswerRelevancyMetric._a_generate_statements\u001b[0;34m(self, actual_output)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatements\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39ma_generate(prompt)\n\u001b[1;32m    246\u001b[0m     data \u001b[38;5;241m=\u001b[39m trimAndLoadJson(res, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatements\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m, in \u001b[0;36mAWSBedrock.a_generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ma_generate\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     21\u001b[0m     chat_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m---> 22\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat_model\u001b[38;5;241m.\u001b[39mainvoke(prompt)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    305\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    306\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 307\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    308\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    309\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    310\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    311\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    312\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    313\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    314\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ChatGeneration, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:796\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    790\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    794\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    795\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m    797\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    798\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:756\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    745\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    746\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    754\u001b[0m             ]\n\u001b[1;32m    755\u001b[0m         )\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    757\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    758\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    760\u001b[0m ]\n\u001b[1;32m    761\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:234\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:924\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 924\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[1;32m    925\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:964\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agenerate\u001b[39m(\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    958\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    962\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m    963\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate,\n\u001b[1;32m    967\u001b[0m         messages,\n\u001b[1;32m    968\u001b[0m         stop,\n\u001b[1;32m    969\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mget_sync() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    971\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/runnables/config.py:588\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    590\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, wrapper)),\n\u001b[1;32m    591\u001b[0m     )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(executor_or_config, wrapper)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/futures.py:285\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_core/runnables/config.py:579\u001b[0m, in \u001b[0;36mrun_in_executor.<locals>.wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_aws/chat_models/bedrock.py:551\u001b[0m, in \u001b[0;36mChatBedrock._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[1;32m    549\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 551\u001b[0m     completion, tool_calls, llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_input_and_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# usage metadata\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usage \u001b[38;5;241m:=\u001b[39m llm_output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py:840\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[0;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    839\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     text \u001b[38;5;241m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/langchain_aws/llms/bedrock.py:826\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[0;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         request_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m     (\n\u001b[1;32m    829\u001b[0m         text,\n\u001b[1;32m    830\u001b[0m         tool_calls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m         stop_reason,\n\u001b[1;32m    834\u001b[0m     ) \u001b[38;5;241m=\u001b[39m LLMInputOutputAdapter\u001b[38;5;241m.\u001b[39mprepare_output(provider, response)\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/function-calling-project--WifTobU-py3.10/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mThrottlingException\u001b[0m: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ServiceUnavailableException) when calling the InvokeModel operation: Bedrock is unable to process your request.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ServiceUnavailableException) when calling the InvokeModel operation: Bedrock is unable to process your request.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n",
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation: Too many requests, please wait before trying again. You have sent too many requests.  Wait before trying again.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.dataset import EvaluationDataset\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.3,\n",
    "    model=aws_bedrock,\n",
    "    include_reason=False # can be changed to false later\n",
    "    )\n",
    "\n",
    "test_cases = []\n",
    "\n",
    "for message, response in zip(batch_message, responses):\n",
    "\n",
    "    input = message[1]['content']\n",
    "    actual_output = response.content\n",
    "\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output)\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "dataset = EvaluationDataset(test_cases=test_cases)\n",
    "dataset.evaluate([metric])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "function-calling-project-_d8EX7TE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
