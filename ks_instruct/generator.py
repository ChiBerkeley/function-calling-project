from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate
from langchain_experimental.tabular_synthetic_data.base import (
    SyntheticDataGenerator,
)
from langchain_experimental.tabular_synthetic_data.prompts import (
    SYNTHETIC_FEW_SHOT_PREFIX,
    SYNTHETIC_FEW_SHOT_SUFFIX,
)
from langchain_ollama import OllamaLLM, ChatOllama

import time

from pydantic import BaseModel
from typing import Dict
import json
import re


class Answer(BaseModel):
    function: str
    arguments: Dict[str, str]


class func_calls(BaseModel):
    query: str
    answer: Answer


llm = OllamaLLM(model="llama3.1", temperature=0.7)
# llm = ChatOllama(model="llama3", temperature=0.7)


examples = [
    {"example": """{{"query": "What is the weather in Paris", "answer": {{"function": "get_weather", "arguments": {{"city": "Paris"}}}}}}"""},
    {"example": """{{"query": "What is the weather in London", "answer": {{"function": "get_weather", "arguments": {{"city": "London"}}}}}}"""},
    {"example": """{{"query": "Translate "Good morning"" to French, "answer": {{"function": "translate", "arguments": {{"text": "Good morning", "target_language": "French"}}}}}}"""},
    {"example": """{{"query": "What is the area of a square with length 1 and width 2 when rounded to the nearest int", "answer": {{"function": "calculate_area", "arguments": {{"length": "1", "width": "2", "round_result": "True"}}}}}}"""},
]


OPENAI_TEMPLATE = PromptTemplate.from_template(template="{example}")

prompt_template = FewShotPromptTemplate(
    prefix=SYNTHETIC_FEW_SHOT_PREFIX,
    examples=examples,
    suffix=SYNTHETIC_FEW_SHOT_SUFFIX, 
    input_variables=["subject", "extra"],
    example_prompt=OPENAI_TEMPLATE,
)

synthetic_data_generator = SyntheticDataGenerator(template=prompt_template, llm=llm, output_schema=func_calls)


def generate_synthetic_data(runs=1):
    """
    Generates synthetic data by invoking the synthetic_data_generator with specified parameters.
    Args:
        runs (int, optional): The number of times to run the data generation process. Defaults to 1 as anything more currently breaks the pipeline.
    Returns:
        list: A list of synthetic results generated by the synthetic_data_generator. Len(synthetic_results) == runs.
    Example:
        synthetic_results = generate_synthetic_data(runs=1)
    """
    start_time = time.time()
    synthetic_results = synthetic_data_generator.generate(
        # Example count is more accurate for lower numbers. 600 only generated 90 examples. The LLM can only generate about 90 examples at a time and runs out of tokens (on prem MBP 16" M1 Max 64GB RAM)
        # subject="queries for function that counts specific given letter; it takes two arguments one is a word and the other is a single letter",
        # extra="the arguments must be chosen at random. Make it a made up word. Don't use the same argument twice. Don't make chit-chat and don't have an introduction. Generate 50 examples",
        subject="queries for function that calculates an area of a square or rectangle; it takes 3 arguments length: float, width: float, round_result: bool",
        extra="the arguments must be chosen at random. Make all the legnths be floats to the hundreth decimal. Don't make chit-chat and don't have an introduction. Generate 40 examples",
        runs=runs,
    )
    end_time = time.time()

    print(f"It took {end_time - start_time:.2f}seconds to generate data")
    return synthetic_results


data = generate_synthetic_data(runs=1)
print(data)


def fix_json_quotes(json_str):
    json_str = re.sub(r'\"([a-zA-Z]+)\"', r'\\\"\1\\\"', json_str)
    json_str = re.sub(r"'([a-zA-Z])'", r'"\1"', json_str)

    return json_str


def validate_and_fix_json(json_str):
    try:
        parsed_data = json.loads(json_str)
        return parsed_data
    except json.JSONDecodeError:
        fixed_json_str = fix_json_quotes(json_str)
        try:
            parsed_data = json.loads(fixed_json_str)
            return parsed_data
        except json.JSONDecodeError as e:
            print(f"Failed to fix JSON: {e}")
            return None
        

json_strings = data[0].split('\n\n')

parsed_json_objects = []
for json_str in json_strings:
    fixed_json = validate_and_fix_json(json_str)
    if fixed_json:
        parsed_json_objects.append(fixed_json)
    else:
        print(f"Skipping invalid JSON string: {json_str}")

combined_json = json.dumps({"queries": parsed_json_objects}, indent=4)

with open('ks_instruct/dump_json/calculate_area/calculate_area.json', 'w') as json_file:
    json_file.write(combined_json)
